<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://pythonandseo.com</id>
    <title>PythonAndSeo</title>
    <updated>2021-12-08T06:34:09.314Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://pythonandseo.com"/>
    <link rel="self" href="https://pythonandseo.com/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://pythonandseo.com/images/avatar.png</logo>
    <icon>https://pythonandseo.com/favicon.ico</icon>
    <rights>All rights reserved 2021, PythonAndSeo</rights>
    <entry>
        <title type="html"><![CDATA[通过bing获取潜在客户电话，邮箱]]></title>
        <id>https://pythonandseo.com/post/as/</id>
        <link href="https://pythonandseo.com/post/as/">
        </link>
        <updated>2021-12-08T03:12:14.000Z</updated>
        <content type="html"><![CDATA[<p>公司做的是传感器行业，属于上游企业，下游很多生产厂家需要用到传感器，以此为背景，编写爬虫帮助公司获取潜在客户邮箱，电话，这里以<strong>CO2 DETECTION</strong>这个关键词为例，如需获取其他产品，只需要更换关键词即可</p>
<h3 id="1根据关键词生成bing-base_url">1.根据关键词生成bing base_url</h3>
<pre><code class="language-python">import re


def get_bing_url(keywords):
    keywords = keywords.strip('\n')
    bing_url = re.sub(r'^', 'https://www.bing.com/search?q=', keywords)
    bing_url = re.sub(r'\s', '+', bing_url)
    return bing_url


if __name__ == '__main__':
    bing_url = get_bing_url('CO2 DETECTION')
    print(bing_url)

</code></pre>
<h3 id="2根据bing翻页规则模拟bing翻页链接">2.根据bing翻页规则，模拟bing翻页链接</h3>
<pre><code class="language-python">bing_url = get_bing_url(keywords.keywords)
    for i in range(1, 100):  # 通过for in来翻页
        print(i)
        time.sleep(random.randint(3, 5))
        if i == 1:
            url = bing_url
        else:
            url = bing_url + '&amp;qs=ds&amp;first=' + str((i * 10) - 1) + '&amp;FORM=PERE'
</code></pre>
<h3 id="3使用selenium模拟打开链接获取网站源码">3.使用selenium模拟打开链接，获取网站源码</h3>
<p>我这里用的是selenium，模拟游览器打开翻页，当然也可以用requests(访问量大的话，爬取的数据相同，所以更换selenium)</p>
<pre><code class="language-python">        try:
            browser.set_page_load_timeout(100)  # 设置网页加载超时时间为20秒
            browser.get(url)
            cookie_ = browser.get_cookies()
            # browser.add_cookie(cookie_dict=cookie_)
            html = browser.page_source
        except Exception as e:
            with open('error.txt', 'a', encoding='utf-8') as f:
                f.write(str(e) + '\n')
            pass
</code></pre>
<h3 id="4利用xpath获取网站源码从中提取url">4.利用xpath获取网站源码，从中提取url</h3>
<pre><code class="language-python">tree = etree.HTML(html)
            li_list = tree.xpath('//ol[@id=&quot;b_results&quot;]//li[@class=&quot;b_algo&quot;]')
            for li in li_list:
                try:
                    url_text = li.xpath('./div/a/@href')[0]
                    # print(url_text)
                except Exception as e:
                    with open('url.txt', 'a', encoding='utf-8') as f:
                        f.write(str(e) + url + '\n')
                    pass
                else:
                    domain_pattern = re.compile(r'[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+\.?')
                    domain_text = re.search(r'[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+\.?',url_text).group()
                    print(domain_text)
                    domain = Domain.objects.filter(domain=domain_text).exists()
                    if domain:
                        print('domain存在:' + url_text)
                        pass
                    else:
                        domain = Domain(domain=domain_text, keywords=keywords)
                        domain.save()
                    pass
</code></pre>
<p>在这个使用了正则获取链接中域名，因为有可能一个产品有很多不同的链接，减少工作量，直接以域名去重</p>
<h3 id="5完整代码如下">5.完整代码如下</h3>
<pre><code class="language-python">import requests
import re
from lxml.html import etree
import os, sys
import django
from workhelp import settings
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time
import random

sys.path.append('../../')
os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;workhelp.settings&quot;)
django.setup()
from infomation.models import Domain, KeyWords

chrome_options = Options()
# chrome_options.add_argument('--headless')
chrome_options.add_argument(
    'user-agent=&quot;Mozilla/5.0 (iPod; U; CPU iPhone OS 2_1 like Mac OS X; ja-jp) AppleWebKit/525.18.1 (KHTML, like Gecko) Version/3.1.1 Mobile/5F137 Safari/525.20&quot;')
chrome_options.add_argument('--log-level=3')
browser = webdriver.Chrome(chrome_options=chrome_options)


def get_bing_url(keywords):
    keywords = keywords.strip('\n')
    bing_url = re.sub(r'^', 'https://www.bing.com/search?q=', keywords)
    bing_url = re.sub(r'\s', '+', bing_url)
    return bing_url


keywords_list = KeyWords.objects.all().filter(status=True)
for keywords in keywords_list:
    bing_url = get_bing_url(keywords.keywords)
    for i in range(1, 100):  # 通过for in来翻页
        print(i)
        time.sleep(random.randint(3, 5))
        if i == 1:
            url = bing_url
        else:
            url = bing_url + '&amp;qs=ds&amp;first=' + str((i * 10) - 1) + '&amp;FORM=PERE'
        try:
            browser.set_page_load_timeout(100)  # 设置网页加载超时时间为20秒
            browser.get(url)
            cookie_ = browser.get_cookies()
            # browser.add_cookie(cookie_dict=cookie_)
            html = browser.page_source
        except Exception as e:
            with open('error.txt', 'a', encoding='utf-8') as f:
                f.write(str(e) + '\n')
            pass
        else:
            tree = etree.HTML(html)
            li_list = tree.xpath('//ol[@id=&quot;b_results&quot;]//li[@class=&quot;b_algo&quot;]')
            for li in li_list:
                try:
                    url_text = li.xpath('./div/a/@href')[0]
                    # print(url_text)
                except Exception as e:
                    with open('url.txt', 'a', encoding='utf-8') as f:
                        f.write(str(e) + url + '\n')
                    pass
                else:
                    domain_pattern = re.compile(r'[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+\.?')
                    domain_text = re.search(r'[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(\.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+\.?',url_text).group()
                    print(domain_text)
                    domain = Domain.objects.filter(domain=domain_text).exists()
                    if domain:
                        print('domain存在:' + url_text)
                        pass
                    else:
                        domain = Domain(domain=domain_text, keywords=keywords)
                        domain.save()
                    pass
    keywords.status = False
    keywords.save()

</code></pre>
<p>简单的说一下上面代码，我是使用django搭建的模型，所以我直接与django模型进行了结合。有不懂得小伙伴可以直接留言与我联系。</p>
<h3 id="6域名提取到了接下来就是打开链接查找邮箱电话进行开发了">6.域名提取到了，接下来就是打开链接，查找邮箱，电话，进行开发了</h3>
<p>作为一名会写程序的SEOer，肯定不会这样做，我们继续使用上面的方法，直接模拟浏览器打开，获取源码，保存数据库，并将打开的页面截图，方便业务人员区分是否是潜在客户，这仅仅是一个思路，有更好的方法可以一起探讨，代码如下</p>
<pre><code class="language-python">import os
import django
import re
import datetime
import uuid
import sys

sys.path.append('../../')
from workhelp import settings
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;workhelp.settings&quot;)
django.setup()


def replaceCharEntity(htmlstr):
    &quot;&quot;&quot;
    替换常用HTML字符
    :param htmlstr: 要替换的字符
    :return:
    &quot;&quot;&quot;
    CHAR_ENTITIES = {'nbsp': ' ', '160': ' ',
                     'lt': '&lt;', '60': '&lt;',
                     'gt': '&gt;', '62': '&gt;',
                     'amp': '&amp;', '38': '&amp;',
                     'quot': '&quot;', '34': '&quot;', }
    re_charEntity = re.compile(r'&amp;#?(?P&lt;name&gt;\w+);')
    sz = re_charEntity.search(htmlstr)
    while sz:
        entity = sz.group()  # entity全称，如&gt;
        key = sz.group('name')  # 去除&amp;;后entity,如&gt;为gt
        try:
            htmlstr = re_charEntity.sub(CHAR_ENTITIES[key], htmlstr, 1)
            sz = re_charEntity.search(htmlstr)
        except KeyError:
            # 以空串代替
            htmlstr = re_charEntity.sub('', htmlstr, 1)
            sz = re_charEntity.search(htmlstr)
    return htmlstr


def filter_tags(htmlstr):
    &quot;&quot;&quot;
    过滤HTML中的标签
    :param htmlstr: 要过滤的内容
    :return:
    &quot;&quot;&quot;
    re_cdata = re.compile('//&lt;!\[CDATA\[[^&gt;]*//\]\]&gt;', re.I)  # 匹配CDATA
    re_script = re.compile('&lt;\s*script[^&gt;]*&gt;[^&lt;]*&lt;\s*/\s*script\s*&gt;', re.I)  # Script
    re_style = re.compile('&lt;\s*style[^&gt;]*&gt;[^&lt;]*&lt;\s*/\s*style\s*&gt;', re.I)  # style
    re_br = re.compile('&lt;br\s*?/?&gt;')  # 处理换行
    re_h = re.compile('&lt;/?\w+[^&gt;]*&gt;')  # HTML标签
    re_comment = re.compile('&lt;!--[^&gt;]*--&gt;')  # HTML注释
    s = re_cdata.sub('', htmlstr)  # 去掉CDATA
    s = re_script.sub('', s)  # 去掉SCRIPT
    s = re_style.sub('', s)  # 去掉style
    s = re_br.sub('\n', s)  # 将br转换为换行
    s = re_h.sub('', s)  # 去掉HTML 标签
    s = re_comment.sub('', s)  # 去掉HTML注释
    # 去掉多余的空行
    blank_line = re.compile('\n+')
    s = blank_line.sub(' ', s)
    s = replaceCharEntity(s)  # 替换实体
    return s


from infomation.models import Domain,Info

while True:
    urls = Domain.objects.all().filter(is_cut=False)[:300]
    print(urls.count())
    chrome_options = Options()
    # chrome_options.add_argument('--headless')
    # chrome_options.add_argument(
    #     'user-agent=&quot;Mozilla/5.0 (iPod; U; CPU iPhone OS 2_1 like Mac OS X; ja-jp) AppleWebKit/525.18.1 (KHTML, like Gecko) Version/3.1.1 Mobile/5F137 Safari/525.20&quot;')
    chrome_options.add_argument('--log-level=3')
    browser = webdriver.Chrome(chrome_options=chrome_options)
    for url in urls:
        print(url.domain)
        pic_path = os.path.join(settings.MEDIA_ROOT, 'images', 'jietu')
        if not os.path.exists(pic_path):
            os.makedirs(pic_path)
        else:
            pass
        try:
            browser.set_page_load_timeout(100)  # 设置网页加载超时时间为20秒
            browser.get('http://'+url.domain)
            html = browser.page_source
            s = filter_tags(html)
            pic_name = '{}.{}'.format(url, '.png')
            browser.get_screenshot_as_file(os.path.join(pic_path, pic_name))

        except Exception as e:
            with open('error.txt', 'a', encoding='utf-8') as f:
                f.write(str(e) + '\n')
            pass
        else:
            pic_path = os.path.join('images', 'jietu', pic_name)
            url = Domain.objects.get(domain=url)
            url.image = pic_path
            url.html = html
            url.content = s
            url.is_cut = True
            url.save()
            # email_pattern = re.compile(r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,3}')
            # emails = email_pattern.findall(html)
            # new_emails = list(set(emails))
            # print(new_emails)
            # emails_str = ','.join(new_emails)
            # print(emails_str)
            # info = Info(email=emails_str, url=url)
            # info.save()

    browser.quit()

</code></pre>
<p>最后就是利用正则，或者其他方法，分析源码，从中提取信息</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[什么是 Google Ads 竞价]]></title>
        <id>https://pythonandseo.com/post/shi-me-shi-google-ads-jing-jie/</id>
        <link href="https://pythonandseo.com/post/shi-me-shi-google-ads-jing-jie/">
        </link>
        <updated>2021-12-08T02:09:41.000Z</updated>
        <content type="html"><![CDATA[<h3 id="google-ads-竞价的运作机制">Google Ads 竞价的运作机制</h3>
<p>Google Ads 采用一种竞价系统来排列搜索结果页上广告的展示顺序和决定每次广告点击的费用。广告在网页上展示的顺序取决于一项称作“广告评级”的计算。</p>
<p>首先，Google 用户希望看到的广告与自己切实相关。他们不愿意看到与自己所搜索的内容没有密切关系的广告。广告主也希望展示具有相关性的广告，这样才会有效吸引用户点击。</p>
<p>Google 希望为用户提供良好的体验，并为广告主创造价值，这样他们今后才愿意再次使用我们的服务。</p>
<p>Google 采用一种特殊的次高价格竞价机制，这种机制不止考虑出价（后面会详细介绍）。在只考虑出价的标准次高价格竞价中，广告主无需全额支付出价金额，只需支付比次高出价金额高 0.01 美元的费用即可。</p>
<p>假设有四家广告主出价竞争搜索结果页上的广告空间，每有一位用户点击他们的广告并访问他们的网站，他们分别愿意支付 4 美元、3 美元、2 美元和 1 美元。</p>
<p>在这种情况下，最高出价为 4 美元，但该广告主只需支付 3.01 美元，也就是比次高出价 3 美元多出 0.01 美元。次高出价和第三高出价的广告主也是如此。在这种机制下，每位广告主都可以实实在在地按照他们愿意为每次点击支付的最高金额出价，但只需支付足以击败对手的金额。</p>
<h3 id="广告评级如何决定广告排名">广告评级如何决定广告排名</h3>
<p>Google Ads 会为参与竞价的每个广告计算广告评级。广告评级决定了广告排名以及您的广告是否有资格展示。一般而言，广告评级最高的广告会展示在首位，广告评级第二高的广告会展示在第二个位置（假设广告达到了评级门槛要求），以此类推。<br>
概括来讲，广告评级由以下五个因素共同决定。</p>
<ol>
<li>
<p><strong>出价</strong>：设置出价是指告诉 Google Ads 您愿意为每次广告点击支付的最高金额。您最终实际支付的金额通常会低于您设置的出价金额，并且您可以随时更改出价。</p>
</li>
<li>
<p><strong>广告评级门槛</strong>：为确保展示的是优质广告，我们设定了最低质量要求，广告必须达到该最低要求才能在特定广告位置展示。</p>
</li>
<li>
<p><strong>查询时的情境</strong>：在广告竞价中，用户当前所处的情境非常重要。计算广告评级时，我们会分析用户输入的搜索字词、用户搜索时所在的位置、用户使用的设备类型（如移动设备或桌面设备）、搜索时间、搜索字词的性质、网页上显示的其他广告和搜索结果，以及其他用户信号和属性。</p>
</li>
<li>
<p><strong>广告附加信息的影响</strong>：制作广告时，您可以向广告中添加一些额外的信息，例如添加电话号码，或添加更多指向您网站上具体网页的链接。此类信息就称为“广告附加信息”。Google Ads 会评估您使用的附加信息及其他广告格式对广告的效果将有何影响。</p>
</li>
<li>
<p><strong>竞价时的广告质量</strong>：Google Ads 还会分析：对于将会看到广告的用户来说，您的广告及其链接到的网站的相关程度和实用性如何。质量得分是一个综合估算值，体现了我们对广告质量的评估结果。</p>
</li>
</ol>
<h3 id="决定广告质量的三个主要因素">决定广告质量的三个主要因素</h3>
<p>广告主只有在自己的广告真正获得点击时，才需要付费；广告的排名不仅仅取决于出价。为什么呢？因为我们希望把比较有用的广告展示在搜索结果页面中排名靠前的位置。下面就来详细了解一下哪些因素决定着广告的质量。</p>
<ol>
<li>
<p><strong>预计点击率</strong>：这是我们预计广告在展示时将获得点击的可能性。在 Google 整个公司，我们都是根据用户反馈来做出决策，而用户点击率 (CTR) 就很好地体现了用户的反应。这相当于让用户通过决定是否点击来投票，这样我们就征集到了数百万用户的意见，有助于我们确定对于每一次搜索查询，哪些广告最为合适。</p>
</li>
<li>
<p><strong>广告着陆页体验</strong>：用户希望广告着陆页能够帮助他们找到所需的内容。着陆页的相关程度越高，广告的评分也就越高。高质量的着陆页应包含合适的原创内容，能够帮助用户完成任务。着陆页应易于导航，一目了然地说明业务的性质、网站是如何与用户计算机交互的以及网站打算如何使用用户的个人信息。</p>
</li>
<li>
<p><strong>广告相关性</strong>：广告相关性用于衡量广告与用户搜索内容的匹配程度，有助于确保只展示对用户有用的广告。这样也就不会导致商家付费投放广告，却在用户搜索与其产品或服务无关的内容时展示了。</p>
</li>
</ol>
<h3 id="广告评级如何影响实际的每次点击费用">广告评级如何影响实际的每次点击费用</h3>
<p>平均每次点击费用 (CPC) 通常并不是您为每次点击支付的价格。由于系统是动态变化的，不同竞价的每次点击费用可能会有很大差异，这取决于各种因素，例如用户每次查询时所处的情境。务必要注意的是，平均每次点击费用只是一个平均值，也就是说您支付的价格可能高于或低于该平均值。</p>
<p>质量较高的广告通常能够以较低的价格获得较为理想的广告排名，广告效果也就更好。用户看到的广告越好，他们就越满意，实际点击这些广告的可能性也就越高。</p>
<h3 id="如何提升广告评级">如何提升广告评级</h3>
<p>具体内容包括质量得分的定义，以及如何提升预计点击率、广告相关性和着陆页体验。</p>
<ol>
<li>
<p><strong>什么是质量得分</strong>:质量得分估算的是广告、关键字和着陆页的质量。质量较好的广告能够以更低的价格获得更好的广告排名。影响质量得分的因素有<strong>预计点击率、广告相关性和着陆页体验</strong>。</p>
</li>
<li>
<p><strong>如何在 Google Ads 中找到质量得分</strong>:通过 Google Ads 界面中的四个质量得分状态列，就可以了解您当前的质量得分及其各个组成要素的得分，即：质量得分、着陆页体验、广告相关性和预计点击率 (eCTR)。如需了解如何查看状态列，请<a href="https://support.google.com/google-ads/answer/6167118?visit_id=637630323825585702-3238729685&amp;rd=1" title="参阅这些说明">参阅这些说明</a>。</p>
</li>
</ol>
<p><strong>提示</strong>：您应使用所有适合您业务的广告附加信息，因为计算广告评级时会考虑广告附加信息的预期影响。有关更多详情，请参阅此最佳做法指南：<a href="https://support.google.com/google-ads/answer/6167123" title="参考质量得分做出优化决策">参考质量得分做出优化决策</a>。</p>
<h3 id="要提高广告质量可以重点提升质量得分的三个组成要素">要提高广告质量，可以重点提升质量得分的三个组成要素</h3>
<ol>
<li>
<p>预计点击率 (eCTR) 用于预测您的关键字是否有可能带来广告点击。不过，您应该着力提高的是点击率 (CTR)，即看到您广告的用户中实际点击广告的用户占比。</p>
<p><strong>广告内容要有针对性</strong>：在广告文字中加入关键字（特别是在标题中），让用户可以看出您的广告与他们搜索的内容直接相关。</p>
<p><strong>尝试使用不同的号召性用语</strong>：您提供免费送货或免费退货服务吗？是想要用户立即致电还是立即预订？</p>
<p><strong>强调产品或服务的独特优势</strong>：是什么让您在竞争中脱颖而出？不妨想一想用户看重的是什么（比如极佳的保修服务或十分宽松的退货政策）。</p>
<p><strong>广告文字要因时因地而异</strong>：在节日或特别活动前后，可以测试旺季专用的广告素材；也可以测试针对地点进行了优化的广告素材。</p>
</li>
<li>
<p>要提高广告的相关性，建议您做到以下几点：</p>
<p><strong>添加否定关键字</strong>：以免在用户搜索查询您排斥的内容或者与您的产品或服务不紧密相关的内容时展示您的广告。</p>
<p><strong>在移动设备上要有针对性</strong>：如果用户在移动设备上的搜索体验与在桌面设备上不同，不妨测试专门针对移动设备的广告素材。</p>
<p><strong>本土化</strong>：为了定位到适合您开展业务的区域，请只使用相关的语言和地理位置。</p>
<p><strong>在广告文案中加入相关的搜索字词</strong>：在广告文案中添加与您的业务相关的搜索字词，可以让您的广告更能引起用户共鸣。</p>
</li>
<li>
<p>要改进着陆页体验，建议您做到以下几点：</p>
<p><strong>将流量引导至合适的着陆页</strong>：用户点击后，应将用户引导至与用户查询的内容相关的页面。如果用户搜索“条纹衬衫”，那么着陆页就应该介绍条纹衬衫，而不是一些其他款式的衬衫或笼统的服装。</p>
<p><strong>内容要一致</strong>：确保着陆页自然接棒广告，继续介绍广告中宣传的产品/服务或引导用户完成广告中号召的行动。</p>
<p><strong>网站内容一目了然、值得信赖</strong>：让访客能够轻松找到您的联系信息，同时清楚明确地介绍您的业务。如果您要求客户提供个人信息，请明确说明索取这些信息的目的，以及您将如何处理和使用它们。</p>
<p><strong>着力提升加载速度和明晰程度</strong>：首屏上展示的内容要主次分明，以便用户快速找到他们要找的内容。</p>
<p><strong>重新思考移动设备体验</strong>：移动网站的用户更重视导航的便捷性，因此务必要优化移动网站体验。</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://pythonandseo.com/post/hello-gridea/</id>
        <link href="https://pythonandseo.com/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="http://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>